{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "30d22143-c856-458b-99d8-57650ff289d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "import scipy.io as sio\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "56a7daef-7ad8-4fe4-88d3-73776ecd0767",
   "metadata": {},
   "outputs": [],
   "source": [
    "IMG_DIR = \"data/ShanghaiTech/part_B/train_data/images\"\n",
    "GT_DIR  = \"data/ShanghaiTech/part_B/train_data/ground-truth\"\n",
    "OUTPUT_IMG_DIR = \"processed_B_images\"\n",
    "OUTPUT_GT_DIR  = \"processed_B_points\"\n",
    "\n",
    "os.makedirs(OUTPUT_IMG_DIR, exist_ok=True)\n",
    "os.makedirs(OUTPUT_GT_DIR, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b5686a2e-e358-4759-87a7-dcbf703f7a7a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 400/400 [00:31<00:00, 12.71it/s]\n"
     ]
    }
   ],
   "source": [
    "TARGET_SIZE = (512, 512)  # width, height\n",
    "\n",
    "def scale_points(points, orig_w, orig_h, new_w, new_h):\n",
    "    scaled = []\n",
    "    scale_x = new_w / orig_w\n",
    "    scale_y = new_h / orig_h\n",
    "    \n",
    "    for x, y in points:\n",
    "        scaled.append([x * scale_x, y * scale_y])\n",
    "    return np.array(scaled)\n",
    "\n",
    "for img_name in tqdm(os.listdir(IMG_DIR)):\n",
    "    if img_name.endswith(\".jpg\"):\n",
    "        \n",
    "        img_path = os.path.join(IMG_DIR, img_name)\n",
    "        img = cv2.imread(img_path)\n",
    "        orig_h, orig_w = img.shape[:2]\n",
    "\n",
    "        resized_img = cv2.resize(img, TARGET_SIZE)\n",
    "        \n",
    "        mat_path = os.path.join(GT_DIR, \"GT_\" + img_name.replace(\".jpg\", \".mat\"))\n",
    "        mat = sio.loadmat(mat_path)\n",
    "        points = mat[\"image_info\"][0][0][0][0][0]\n",
    "\n",
    "        points_scaled = scale_points(points, orig_w, orig_h, TARGET_SIZE[0], TARGET_SIZE[1])\n",
    "\n",
    "        save_img_path = os.path.join(OUTPUT_IMG_DIR, img_name)\n",
    "        cv2.imwrite(save_img_path, resized_img)\n",
    "\n",
    "        save_points_path = os.path.join(OUTPUT_GT_DIR, img_name.replace(\".jpg\", \".npy\"))\n",
    "        np.save(save_points_path, points_scaled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8c90bf74-b24e-4863-8cc7-03155dedf137",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.ndimage import gaussian_filter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "369f9977-13c8-4f5c-ab26-204003639079",
   "metadata": {},
   "outputs": [],
   "source": [
    "IMG_DIR = \"processed_B_images\"      \n",
    "POINTS_DIR = \"processed_B_points\"     \n",
    "OUTPUT_DENSITY_DIR = \"density_B_maps\"\n",
    "\n",
    "os.makedirs(OUTPUT_DENSITY_DIR, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f2005163-c205-4f15-aa4d-7e930b9f721b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_density_map(points, h, w, sigma=4):\n",
    "    density = np.zeros((h, w), dtype=np.float32)\n",
    "    \n",
    "    for x, y in points:\n",
    "        if 0 <= int(x) < w and 0 <= int(y) < h:\n",
    "            density[int(y), int(x)] = 1\n",
    "    \n",
    "    density = gaussian_filter(density, sigma=sigma)\n",
    "    return density"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "cb8f029a-94b5-4a31-93cd-ba81ff5f3087",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 400/400 [00:37<00:00, 10.80it/s]\n"
     ]
    }
   ],
   "source": [
    "for img_name in tqdm(os.listdir(IMG_DIR)):\n",
    "    if img_name.endswith(\".jpg\"):\n",
    "        \n",
    "        img_path = os.path.join(IMG_DIR, img_name)\n",
    "        img = cv2.imread(img_path)\n",
    "        h, w = img.shape[:2]\n",
    "\n",
    "        points_path = os.path.join(POINTS_DIR, img_name.replace(\".jpg\", \".npy\"))\n",
    "        points = np.load(points_path)\n",
    "\n",
    "        density_map = generate_density_map(points, h, w, sigma=4)\n",
    "\n",
    "        np.save(os.path.join(OUTPUT_DENSITY_DIR, img_name.replace(\".jpg\", \".npy\")), density_map)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "234a7519-ca93-48ef-9a5c-3826ae448d06",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torchvision.transforms as T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "44c66ba2-e367-459a-9c03-eb477071e458",
   "metadata": {},
   "outputs": [],
   "source": [
    "# paths\n",
    "IMG_DIR = \"processed_B_images\"\n",
    "DENSITY_DIR = \"density_B_maps\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0f78744a-80bb-477b-97e4-02e47705b2e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = T.Compose([\n",
    "    T.ToTensor(),  # Convert HWC image to CHW tensor (0–1)\n",
    "    T.Normalize(mean=[0.485, 0.456, 0.406],\n",
    "                std=[0.229, 0.224, 0.225])   # ImageNet normalization\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "09750472-1d1d-4532-857d-2e97f325073f",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CrowdDataset(Dataset):\n",
    "    def __init__(self, img_dir, density_dir, transform=None):\n",
    "        self.img_dir = img_dir\n",
    "        self.density_dir = density_dir\n",
    "        self.transform = transform\n",
    "        self.images = [f for f in os.listdir(img_dir) if f.endswith(\".jpg\")]\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.images)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img_name = self.images[idx]\n",
    "\n",
    "        # Load image\n",
    "        img_path = os.path.join(self.img_dir, img_name)\n",
    "        img = cv2.imread(img_path)\n",
    "        img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "        # Apply transform\n",
    "        if self.transform:\n",
    "            img = self.transform(img)\n",
    "\n",
    "        # Load density\n",
    "        density_path = os.path.join(self.density_dir, img_name.replace(\".jpg\", \".npy\"))\n",
    "        density = np.load(density_path)\n",
    "\n",
    "        # Downsample density map (factor 8)\n",
    "        density_down = cv2.resize(density, (density.shape[1]//8, density.shape[0]//8))\n",
    "\n",
    "        # Multiply by 64 to preserve total count\n",
    "        density_down = density_down * 64\n",
    "\n",
    "        # Convert to tensor\n",
    "        density_tensor = torch.tensor(density_down, dtype=torch.float32).unsqueeze(0)\n",
    "\n",
    "        return img, density_tensor\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "81c7c605-113b-4784-8ae3-ac7eee1b2035",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total samples: 400\n",
      "Image tensor shape: torch.Size([3, 512, 512])\n",
      "Density map shape: torch.Size([1, 64, 64])\n",
      "Estimated count: 233.12474060058594\n"
     ]
    }
   ],
   "source": [
    "dataset = CrowdDataset(IMG_DIR, DENSITY_DIR, transform)\n",
    "train_loader = DataLoader(dataset, batch_size=4, shuffle=True)\n",
    "\n",
    "print(\"Total samples:\", len(dataset))\n",
    "\n",
    "# Example test load\n",
    "img, den = dataset[0]\n",
    "print(\"Image tensor shape:\", img.shape)\n",
    "print(\"Density map shape:\", den.shape)\n",
    "print(\"Estimated count:\", den.sum().item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "709948c7-7f63-4e06-a1d6-0c0d668c6a52",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
